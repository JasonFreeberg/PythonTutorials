{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Science at UCSB\n",
    "\n",
    "# Python for Data Science: Tabular Data\n",
    "\n",
    "## Jason Freeberg, Fall 2016 \n",
    "\n",
    "Tabular data is how a lot data is organized. It is not the *only* data format, but it is the easiest to work with because it is well-structured. Other data formats you will come across include [JSON](http://www.json.org/), [Relational and Non-Relational Databases](https://www.mongodb.com/scale/relational-vs-non-relational-database), images, and audio files. And believe it or not you are already familiar with tabular data, it's simply a table with columns and rows. Just like in Excel.\n",
    "\n",
    "As data scientists to-be, however, we need to make define some terms. We will often refer to rows as *observations* or *records*, and columns as *variables* or *features*. The *header* is the top row containing the names of our variables. In the example below our variables are country, salesperson, order id, and so on. Our observations are individual orders with those variable values. Our header, in this case, would be the row with index #1.\n",
    "\n",
    "![data_pic](http://mothimages.s3.amazonaws.com/tabular_data_1.png)\n",
    "\n",
    "In today's lab we will get acquainted with the [pandas module](http://pandas.pydata.org/) by loading a Comma Seperated Value (.csv) [file](https://archive.ics.uci.edu/ml/datasets/Forest+Fires) from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.html). We will then check it, coerce the variables to the correct format, check for missing values, and create aggregate reports by conditional selection. Then you'll follow the same pipeline on your own with a different dataset!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the modules we'll need and assign the data's URL.\n",
    "\n",
    "# By the way, it's customary to include all module imports at the beginning of your script.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib.requests import urlopen\n",
    "\n",
    "UCI_data_URL = 'http://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A helper function to read the data from the url. \n",
    "# Just run this cell, but understand what the function is doing.\n",
    "\n",
    "\n",
    "def read_csv_from_url(URL):\n",
    "    \"\"\"\n",
    "    Takes as input a string containing the URL pointing to a dataset from the UCI data repository.\n",
    "    Returns a pandas dataframe containing the data with some columns coerced as strings.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = urlopen(URL)\n",
    "    lines = pd.read_csv(response, \n",
    "                        header = 0,\n",
    "                        index_col = False,\n",
    "                        dtype = {'DMC' : str,\n",
    "                                 'temp' : str,\n",
    "                                 'area' : str})\n",
    "    \n",
    "    return pd.DataFrame(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Check Data\n",
    "\n",
    "Using the URL and function above, let's load the data into our notebook as a pandas dataframe. We will then inspect dataframe's size, missing values, and variable types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 8] nodename nor servname provided, or not known>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6503b0145c01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the data and print the head of the dataframe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfire_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUCI_data_URL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Let's check the head and size of our data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-443c34451528>\u001b[0m in \u001b[0;36mread_csv_from_url\u001b[0;34m(URL)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \"\"\"\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mURL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     lines = pd.read_csv(response, \n\u001b[1;32m     13\u001b[0m                         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonfreeberg/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonfreeberg/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonfreeberg/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 449\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonfreeberg/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonfreeberg/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mhttp_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttplib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[0mhttp_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jasonfreeberg/anaconda/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# XXX what error?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1197\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 8] nodename nor servname provided, or not known>"
     ]
    }
   ],
   "source": [
    "# Load the data and print the head of the dataframe.\n",
    "\n",
    "fire_df = read_csv_from_url(UCI_data_URL)\n",
    "\n",
    "# Let's check the head and size of our data\n",
    "\n",
    "print(fire_df.head())\n",
    "print(\"Number of rows:\", fire_df.shape[0])\n",
    "print(\"Number of columns:\", fire_df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our data loaded and assigned as a pandas.DataFrame object. However, I made a *slight* adjustment and loaded some variables as **strings**. Know that the pandas DataFrame( ) method is very well built and could have inferred the correct types for all columns, but variable coersion is a common data preparation task so we will do it in this lab.\n",
    "\n",
    "**Right now we'll check for missing and incorrect values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fire_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3d87f8eccc9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# We can use the sum() method to take the sums by each column. Remember that True = 1, False = 0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlogical_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfire_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlogical_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fire_df' is not defined"
     ]
    }
   ],
   "source": [
    "# .isnull() returns a dataframe of logical (T/F) entries where True = Is_Null and False = Not_Null.\n",
    "# We can use the sum() method to take the sums by each column. Remember that True = 1, False = 0.\n",
    "\n",
    "logical_dataframe = fire_df.isnull()\n",
    "print(logical_dataframe.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we don't have any **NaN** or **None** values in our columns. But we're not out of the woods yet. Let's take a look at our categorical variables and check that they're reasonable. By printing out the unique strings in each column, we'll be able to see if there are any inappropriate values like misspelled days or months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class of our returned column:"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fire_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-04ba59276dfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# We can use the unique() method to get the distinct strings held in the Series object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Class of our returned column:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfire_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mfire_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mfire_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mday\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fire_df' is not defined"
     ]
    }
   ],
   "source": [
    "# The syntax, \"dataFrame.columnName\" will return a pandas Series object. \n",
    "# We can use the unique() method to get the distinct strings held in the Series object. \n",
    "\n",
    "print(\"Class of our returned column:\", type(fire_df.month))\n",
    "print(fire_df.month.unique())\n",
    "print(fire_df.day.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily for us the UCI datasets are often very clean. Although we didn't uncover any missing or incorrect values in this dataset, these types of checks will become routine when you start a project or intern at a company.\n",
    "\n",
    "**Now we'll look at our column types and make adjustments as necessary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This will show our columns and their corresponding types.\n",
    "print('The data types of our features:')\n",
    "print(fire_df.dtypes, '\\n')\n",
    "\n",
    "# That's a lot to look at, let's narrow our search. This is a conditional selection, which we'll get to later.\n",
    "print('Our non-numeric variables:')\n",
    "print(fire_df.dtypes[fire_df.dtypes == 'object']) # Condition is in the square brackets.\n",
    "\n",
    "# Month and day are okay being objects (strings), but those other three need to be converted to floats...\n",
    "fire_df.DMC = fire_df.DMC.astype(float)\n",
    "fire_df.area = fire_df.area.astype(float)\n",
    "fire_df.temp = fire_df.temp.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional Selection\n",
    "\n",
    "Now that we have vetted the data for discrepancies, we can create do some exploratory analysis. Let's first cover conditional selection. Our data is 517 x 13, but we often won't want to use the entire table all the time. We might only need a couple columns, or perhaps we only want to look at the data on Tuesdays. With pandas, it's easy to select columns and rows based on arbitrary conditions. \n",
    "\n",
    "- Here's the basic syntax: *dataframe*[*condition on **rows***]\\[*names or numbers of **columns***]\n",
    "- Alternatively... *dataframe*.ix[*condition on **rows***, *selection of **columns*** ]\n",
    "  - If you come from an R background, the .ix attribute syntax may seem familiar\n",
    "- use *dataframe*.iloc**[ ]** for selecting rows and columns based on **purely numerical** indices\n",
    "\n",
    "Click [here](http://pandas.pydata.org/pandas-docs/stable/indexing.html) for the full documentation on slicing and dicing pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fire_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-46d5cb234f44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Filter rows...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfire_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# prints first ten rows (from 0 to 9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfire_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# same as above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfire_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# same again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfire_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfire_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marea\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fire_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Filter rows...\n",
    "fire_df[:5]  # prints first ten rows (from 0 to 9)\n",
    "fire_df.iloc[:5]  # same as above\n",
    "fire_df.iloc[[1,2,3,4,5]]  # same again\n",
    "fire_df[fire_df.area > 30]\n",
    "fire_df[ (fire_df.area > 30) & (fire_df.rain > 10) ]  # two conditions on rows\n",
    "\n",
    "# Select columns...\n",
    "fire_df.temp  # a single column\n",
    "fire_df[\"temp\"]  # also a single column \n",
    "fire_df[['day', 'area', 'rain']]  # multiple columns\n",
    "\n",
    "# Select AND filter...\n",
    "fire_df[fire_df.area > 30][['day', 'area', 'rain']]\n",
    "\n",
    "# Using '.ix' and making the same selection as above...\n",
    "fire_df.ix[ fire_df.area > 30, ['day', 'area', 'rain'] ]\n",
    "\n",
    "# Just to hide output...\n",
    "print(\"Wow Python is so cool!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn\n",
    "\n",
    "Get in the driver's seat, because it's your turn to write some code. Look for the &lt;FILL IN&gt; bits. Good luck and be sure to ask Jason for clarification or help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data from the URL and store it in a pandas dataframe\n",
    "newURL = \"http://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
    "\n",
    "\n",
    "def myCSVReader(a_URL):\n",
    "    #response = <FILL IN>\n",
    "    #lines = pd.<FILL IN>\n",
    "    response = urllib2.urlopen(a_URL)\n",
    "    lines = pd.read_csv(response)\n",
    "  \n",
    "    #return <FILL IN>\n",
    "    return pd.DataFrame(lines)\n",
    "\n",
    "carData = myCSVReader(newURL)\n",
    "\n",
    "carData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uh oh! Looks like our data is missing something, but what?\n",
    "# ... We're missing the header of the data (the column names)!\n",
    "# Here they are.\n",
    "\n",
    "colNames = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\", \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\", \"wheelbase\", \"length\", \"width\", \"height\", \"curb_weight\", \"engine_type\", \"num_cylinders\", \"engine_size\", \"fuel_system\", \"bore\", \"stroke\", \"compression_ratio\", \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]\n",
    "\n",
    "# Now edit our CSV reader to accept a list of column names and then use it to set the DataFrame's column names.\n",
    "# Look around online to find the DataFrame attribute you need to set ;)\n",
    "\n",
    "def myCSVReader(a_URL, column_names):\n",
    "    response = urllib2.urlopen(a_URL)\n",
    "    lines = pd.read_csv(response)\n",
    "    dataframe = lines\n",
    "    dataframe.columns = column_names\n",
    "  \n",
    "    return pd.DataFrame(lines)\n",
    "\n",
    "carData = myCSVReader(newURL, colNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's practice some conditional selection\n",
    "\n",
    "# Select rows 1, 2, 3 using numeric indices -- all columns\n",
    "test1 = carData.iloc[[1,2,3]]\n",
    "\n",
    "# Select columns 4, 5, 6 using column numbers -- all rows\n",
    "test2 = carData.iloc[:, [4, 5, 6]]\n",
    "\n",
    "# Subset the DataFrame to only sedans\n",
    "test3 = carData[carData.body_style == 'sedan']\n",
    "\n",
    "# Now in those convertible cars, only keep the horsepower, engine size, city MPG, and highway MPG.\n",
    "test4 = test3[['horsepower', 'engine_size', 'city_mpg', 'highway_mpg']]\n",
    "\n",
    "# Now find the mean horsepower!\n",
    "test4[\"horsepower\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Uh-oh! That doesn't seem like a reasonable average horsepower for sedans!\n",
    "# There must be something fishy in the data; let's investigate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
